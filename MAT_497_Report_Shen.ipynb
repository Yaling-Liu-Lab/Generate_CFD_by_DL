{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "fastai v1",
      "language": "python",
      "name": "fastai_v1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "MAT_497_Report_Shen.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuWeaLPKjZFE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "## __A Generative Model Predicting Steady Numerical Simulations via Weakly-supervised Learning__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK3ZcEuvjZFH",
        "colab_type": "text"
      },
      "source": [
        "## Abstract\n",
        "\n",
        "The machine learning method applied to computational fluid dynamics (CFD) is a thriving approach for solving simulation problems. Traditional CFD seeks various approaches or high-performance computational tools to overcome the difficulty of being extremely time-consuming because the simulation process is mostly iterative and mesh-based. The machine learning method is usually data-driven and expedites the simulation process by building up a meshless, data-driven toolbox. However, the simulation results for labels of the training are not always available and can be as expensive. Weakly-supervised learning, as an alternative, has shown the potential for solving Laplace equations. Here we extend the applications to more complicated computational scenarios and show that weakly-supervised learning can be trained to solve the Navier-stokes equation, and to be applied on irregular domains by extending the dimension of data representation. The results shows high accuracy once a proper initialization is given as input. We expect that a similar model can be generalized to solve or to speed up the fluid-structure interaction problems with minimal information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ZWfcdUnPW1",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "Complicated fluid problems are common in many natural processes. A typical fluid problem is governed by a highly nonlinear partial differential equation (PDE) system, Navier Stokes (N-S) equations. Numerical simulations on the fluid dynamics problems primarily rely on solving the PDEs in the discretized form both spatially and temporally in some ways using the finite difference (FD), finite volume (FV), Lattice-Boltzmann, or finite element (FE) methods. However, such simulations are based on the density of meshes thus computationally expensive in both time and memory for complicated fluid-structure interaction problems where complex geometries are applied. Even before the computation, the preprocessing such as the design of meshing is also a huge cumbersome. Although modern commercial software relieves the burden of these preprocessing tasks, background knowledge in numerical simulation and expertise in using such tools are usually necessary for both academic and industrial applications. \n",
        "\n",
        "Machine learning (ML), and especially the deep learning (DL) approaches have been a great success in many areas with the help of large labeled dataset. The supervised tasks of ML assemble labeled data before an architecture fitted to predict the expected results. Recently, DL has shown new promises for numerical simulation due to its capability of handling strong nonlinearity and high dimensionality [*]. However, just like in a typical machine learning task, it is necessary to obtain or create large labeled datasets in order to achieve high performance. The state-of-art architectures of deep learning are dependent on a large amount of training and specially labeled data, but these architectures are hard to be operated when the data becomes sparse and minimal.\n",
        "\n",
        "In typical ML problems, though successful for solving different problems, the mechanism behind the system is complicated, high-dimensional, and usually unknown before fitted with the labeled data. On the contrary, in traditional numerical simulation problems, the governing equations are clearly known, but the equations are difficult to be solved correctly and efficiently. The known governing equations can be utilized to constrain the learning to compensate for the insufficiency of the data. Recently, several groups have established such connections between the governing equations [RASSIs] and the simulation results via the physics-informed loss functions, building up physics-informed neural network (PINN) [PINN]. The loss functions are established according to the residues of each PDE equation that constrain the computational domain that is defined by nodal points. However, in their works, the expectation from the network is to build up a data-driven solver -- to solve general PDEs not by a traditional CFD process, but by a deep and dense artificial neural network (ANN) instead. When multiple parameters in the same form of PDEs are in need to be solved, such trained networks can predict solutions in which parameters within a certain range are applied, but the networks should be re-trained when other geometries, other boundary conditions or initial conditions are applied, which deviates from the motivation of saving computational power.\n",
        "\n",
        "Recently, a weakly-supervised learning paradigm for solving heat equations has shown the potential power of using a similar idea of building loss function to generate the solutions [Sharma]. Instead of the traditional ANN, a fully convolutional encoder-decoder network adapted from the U-Net architecture [Unet] has been implemented to generate the solved domain. This work has combined the idea of physics informed loss that learn physics with a generative model as in [amir] that keep the intrinsic relations between neighboring nodal points. Without allowing the model to get access to any solved simulation data, the trained model can predict the solution with different boundary conditions instantly. Unfortunately, the work brings the idea and only uses the heat equation with Dirichlet boundary conditions as the single example problem. The presented work is an extension along with this idea. Here we try using the idea and extending the complication and dimension of data representation to solve problems with other types of boundary conditions, irregular geometric domain, and a cavity flow problem solved by N-S equations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RnC2CWbbnNS",
        "colab_type": "text"
      },
      "source": [
        "## Install and Import Packages (Code)\n",
        "Import pytorch packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL_InPs9bFmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U scikit_image scikit_learn scipy pytorch\n",
        "!pip install pillow==4.2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfTChQYwbW2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import argparse\n",
        "import os\n",
        "import time\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vurbdjKatHhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e673e318-9b9e-42e5-dbc5-624fa51926bd"
      },
      "source": [
        "# if running on collaboratory set = True\n",
        "collaboratory = True\n",
        "\n",
        "if collaboratory:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "else: \n",
        "    print('Running on local systems, if running on collaboratory please change above')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqFFPc93tIyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7a25765-e8ac-4f40-8a23-6b46e6ca312f"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfUQcd8CtU-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "fd095af2-2b92-4faa-d5ed-eb2199d83745"
      },
      "source": [
        "import os\n",
        "if os.path.exists(\"./generate_CFD\"):\n",
        "    pass\n",
        "else:\n",
        "    ! git clone https://github.com/shenw33/generate_CFD.git"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'generate_CFD'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 21 (delta 5), reused 15 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZYGpIRkttGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b8f0c5d-21e0-456f-db32-910fc931bf72"
      },
      "source": [
        "cd generate_CFD"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/generate_CFD/generate_CFD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj80-qw2t0O1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1233ab0e-9b82-4ed5-d026-df781aa7d267"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGbreZJQudAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "8ec8d87c-57c3-416d-da6a-3aa5e41f64e4"
      },
      "source": [
        "import UNet2 "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b3e475e9ff2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mUNet2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'UNet2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5KgeliykFjK",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "The physics informed loss functions are based on the residue of the PDEs. For example, to solve the 2D steady-state heat equation using finite difference, we need to discretize $\\Delta T = 0$. Considering evenly spaced 2-D grid, the discretized form of $\\Delta T=0$ for the node $(i,j)$ would be:\n",
        "$T_{i,j} = (T_{i+1,j} +T_{i-1,j} +T_{i,j+1} +T_{i,j-1}) / 4$. The nodal relation expressed in the above equation is solved iteratively by applying the rule above at each node (point in the grid) until convergence. We can clearly find that if we define a physics-informed kernel, as shown in figure [], the physics informed loss should be:\n",
        " \n",
        "## Laplace equation with Neumann Boundary conditions:\n",
        "Suppose we define the discretization to be $h$. And there is Neumann boundary condition on the left boundary $T(0,y_j)=a(y_{j})$. Suppose fictitous nodes $T_{-1,j}$:\n",
        "<br>\n",
        " \n",
        "$$\n",
        "T\\left(0, y_{j}\\right) \\approx\\frac{T_{1, j}-T_{-1, j}}{2 h}=a(y_{j})=a_{j}\n",
        "$$\n",
        "So we can rewrite that: $T_{-1, j}=T_{1, j}-2 h a_{j}$. For the nodes at $i=0$, the constraints still hold:\n",
        "<br>\n",
        "$$\n",
        "T_{-1, j}-4 T_{0, j}+T_{1, j}+T_{0, j-1}+T_{0, j+1}=0\n",
        "$$\n",
        "Substitute with the equation for the fictitious nodes\n",
        "$$\n",
        "-4 T_{0, j}+2 T_{1, j}+T_{0, j-1}+T_{0, j+1}=2 h a_{j}\n",
        "$$\n",
        "<br>\n",
        " \n",
        "This equation is the special condition for the boundary nodes, which is similar for the equation governing the internal nodes. For the boundary nodes $T_{0,j}$, if we simplify the $h$ to still be 1, the extra terms for the loss function could be written once we put the padding layers indicating the boundary condition $a_j$, and defined the extra kernel indicating the equation above, and the new kernel compared with the regular kernel applied on the internal nodes could be seen as in figure \n",
        " \n",
        "## Laplace equations with a hollow square inside the computational domain\n",
        "\n",
        "\n",
        "## Navier-stokes equations\n",
        " \n",
        "\n"
      ]
    }
  ]
}